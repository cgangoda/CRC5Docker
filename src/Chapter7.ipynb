{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook examples for Chapter 7\n",
    "# Supervised Classification Part 2\n",
    "Continuing on the subject of supervised\n",
    "classification, Chapter 7  begins with a discussion  of\n",
    "post classification processing methods to\n",
    "improve  results on the basis of contextual\n",
    "information, after which  attention is turned to statistical\n",
    "procedures for evaluating classification accuracy and for making\n",
    "quantitative comparisons between different classifiers. \n",
    "As examples of  _ensembles_  of\n",
    "classifiers, the _adaptive boosting_\n",
    "technique is examined, applying it in particular to improve the generalization\n",
    "accuracy of neural networks, and  the _random forest_ classifier, an ensemble of _binary  decision trees_ is also described. The remainder of the Chapter examines  more specialized forms of supervised image classification, namely as applied to   polarimetric SAR imagery, to data with  hyper-spectral resolution, and to   intermediate and high  resolution multispectral imagery using _convolutional neural networks_, _transfer learning_ and _semantic segmentation_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bCb6fLjJ8W3YsQ7Jmc7f9tyYYUGsURjaIByiGIw_CXE&tc=xXDrW0PIMPwOM6XXR5qEM9SA3K7ZM2v31tF_Uar2vTY&cc=itDbmwY0xgBGod5kKFTNk9bsd8ochrCXYxs40Zzz7XE>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=bCb6fLjJ8W3YsQ7Jmc7f9tyYYUGsURjaIByiGIw_CXE&tc=xXDrW0PIMPwOM6XXR5qEM9SA3K7ZM2v31tF_Uar2vTY&cc=itDbmwY0xgBGod5kKFTNk9bsd8ochrCXYxs40Zzz7XE</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AeanS0bx4GyMoUwwnoWmRwDnA_jHhsjGDYAdxs-gnLBOGeLiZz-lExKK0dA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_0JLhFqfSY1uiEaW?source=Init\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Postprocessing\n",
    "### 7.1.1 Majority filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2. Probabilistic label relaxation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/classify -a 6 -p [1,2,3,4,5] -L [10,10] -e 100 -P imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/dispms -f imagery/AST_20070501_pca_classprobs.tif -e 2 -p [1,2,3] -d [400,400,300,300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/plr -i 3 imagery/AST_20070501_pca_classprobs.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/dispms -f imagery/AST_20070501_pca_class.tif -c -d [400,400,300,300] \\\n",
    "-F imagery/AST_20070501_pca_classprobs_plr.tif -C -D [400,400,300,300] \\\n",
    "#-s '/home/mort/LaTeX/new projects/CRC5/Chapter7/fig7_1.eps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Evaluation and comparison of classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.1 Accuracy assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "theta = 0.4\n",
    "n = 2000\n",
    "x = np.arange(600, 1000)\n",
    "# pmf = probability mass function\n",
    "plt.plot(x, binom.pmf(x, n, theta))\n",
    "\n",
    "#plt.savefig('/home/mort/LaTeX/new projects/CRC4/Chapter7/fig7_2.eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/ct imagery/AST_20070501_pca_NNet(Congrad).tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.2 Accuracy assessment on the GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "# first 4 principal components of ASTER image\n",
    "image = ee.Image('projects/ee-mortcanty/assets/CRC5/AST_20070501_pca') \\\n",
    "                                      .select(0,1,2,3)\n",
    "# training data\n",
    "table = ee.FeatureCollection('projects/ee-mortcanty/assets/CRC5/train')\n",
    "# sample the image with the polygons to a feature  \n",
    "# collection, rename the class id columns from strings \n",
    "# to integers, add a column of random numbers in [0,1]\n",
    "trainTestData = image.sampleRegions(collection=table,\n",
    "                                properties=['CLASS_ID'],\n",
    "                                scale=15) \\\n",
    " .remap(list(map(str,range(10))),list(range(10)),\n",
    "                                           'CLASS_ID') \\\n",
    " .randomColumn('rand',seed=12345) \n",
    "# filter on the random column to split into training and\n",
    "# test feature collections in the ration of 2:1\n",
    "trainData = trainTestData.filter(ee.Filter.lt('rand',0.67))\n",
    "testData = trainTestData.filter(ee.Filter.gte('rand',0.67))\n",
    "print('train pixels: %i'%trainData.size().getInfo())\n",
    "print('test pixels:  %i'%testData.size().getInfo())\n",
    "# train a (default) SVM classifier on training data   \n",
    "classifier = ee.Classifier.libsvm()\n",
    "trained = classifier.train(trainData,'CLASS_ID',\n",
    "                                   image.bandNames()) \n",
    "# test the trained classifier with the test data\n",
    "tested = testData.classify(trained)\n",
    "# generate a confusion matrix with the \n",
    "# classified test data\n",
    "cm = tested.errorMatrix('CLASS_ID','classification')\n",
    "# and from it determine the accuracy and kappa \n",
    "print('accuracy: %f'%cm.accuracy().getInfo())\n",
    "print('kappa:    %f'%cm.kappa().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Crossvalidation on parallel architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ipcluster start -n 4 --daemonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/crossvalidate -p [1,2,3,4,5] -a 6 -e 10 -L [10,10] -e 1000 imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.4 Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4,5] -a 6 -L [10,10] -e 500 imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4,5] -a 7 imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/mcnemar imagery/AST_20070501_pca_SVM.tst \\\n",
    "imagery/AST_20070501_pca_Dnn(tensorflow).tst "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4,5] -a 2  imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/mcnemar imagery/AST_20070501_pca_Gausskernel.tst \\\n",
    "imagery/AST_20070501_pca_Dnn(tensorflow).tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Ensembles\n",
    "### 7.3.1 Adaptive boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/adaboost -p [1,2,3,4,5]  -L 10 -n 50 imagery/AST_20070501_pca.tif  imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/dispms -f imagery/AST_20070501_pca_class.tif -c \\\n",
    "-r  \"['WATER', 'RAPESEED', 'SUGARBEET', 'SUBURBAN', 'INDUSTRIAL', 'CONIFEROUS', 'GRAIN', 'GRASSLAND', 'HERBIFEROUS', 'OPENCAST']\" \\\n",
    "#-s '/home/mort/LaTeX/new projects/CRC5/Chapter7/fig7_x.eps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3.2 Binary decision trees and random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4,5] -a 8  imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/dispms -f imagery/AST_20070501_pca_class.tif -c \\\n",
    "-r  \"['WATER', 'RAPESEED', 'SUGARBEET', 'SUBURBAN', 'INDUSTRIAL', 'CONIFEROUS', 'GRAIN', 'GRASSLAND', 'HERBIFEROUS', 'OPENCAST']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/mcnemar imagery/AST_20070501_pca_Gausskernel.tst \\\n",
    "imagery/AST_20070501_pca_RF.tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Classification of polarimetric SAR imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Hyperspectral image analysis\n",
    "### 7.5.1 Spectral mixture modeling\n",
    "### 7.5.2 Unconstrained linear unmixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "inDataset = gdal.Open('imagery/97_radianz_registriert_voll',GA_ReadOnly)                       \n",
    "cols = inDataset.RasterXSize\n",
    "rows = inDataset.RasterYSize    \n",
    "bands = inDataset.RasterCount\n",
    "print(rows, cols, bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Im = np.zeros((rows,cols,bands)) \n",
    "for b in range(bands):\n",
    "    band = inDataset.GetRasterBand(b+1)\n",
    "    Im[:,:,b] = band.ReadAsArray(0,0,cols,rows)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral cut\n",
    "plt.plot(Im[300,300,:])\n",
    "#plt.savefig('/home/mort/LaTeX/new projects/CRC4/Chapter7/fig7_6.eps',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.3 Intrinsic end-members and pixel purity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/mnf.py imagery/97_radianz_registriert_voll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.4 Anomaly detection: The RX algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/rx imagery/AST_20070501_pca.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/AST_20070501_pca_rx.tif -e 1 -d [600,600,400,400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5.5 Anomaly detection: The kernel RX algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/krx -s 2000 imagery/AST_20070501_pca.tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run scripts/dispms -f imagery/AST_20070501_pca_rx.tif -e 2 -d [600,600,250,250] \\\n",
    "-F imagery/AST_20070501_pca_krx.tif -E 2 -D [600,600,250,250] \\\n",
    "#-s '/home/mort/LaTeX/new projects/CRC5/Chapter7/fig7_9.eps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1 Transfer learning\n",
    "\n",
    "The examples in the text can be run on Google Colab with a GPU runtime. Use this link:\n",
    "\n",
    "https://colab.research.google.com/drive/1aleipk9k16e5jAjR1FqcOl9NB7FUjLng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2 Semantic segmentation\n",
    "\n",
    "These examples should be run on Google Colab with a GPU runtime. Use this link:\n",
    "\n",
    "https://colab.research.google.com/drive/136YAVBZCwppz2SU-6Yxo1q2D2geyq0se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
