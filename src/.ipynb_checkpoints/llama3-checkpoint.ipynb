{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d749a561-c8fc-4991-afe9-7113d3c6017c",
   "metadata": {},
   "source": [
    "### Trying out RAG with ollama\n",
    "ollama is installed in the python environment venvcrc5 from where this notebook is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de73eae-777f-4b14-9ed4-cbdd2cfd4556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language model runner\n",
      "\n",
      "Usage:\n",
      "  ollama [flags]\n",
      "  ollama [command]\n",
      "\n",
      "Available Commands:\n",
      "  serve       Start ollama\n",
      "  create      Create a model from a Modelfile\n",
      "  show        Show information for a model\n",
      "  run         Run a model\n",
      "  stop        Stop a running model\n",
      "  pull        Pull a model from a registry\n",
      "  push        Push a model to a registry\n",
      "  list        List models\n",
      "  ps          List running models\n",
      "  cp          Copy a model\n",
      "  rm          Remove a model\n",
      "  help        Help about any command\n",
      "\n",
      "Flags:\n",
      "  -h, --help      help for ollama\n",
      "  -v, --version   Show version information\n",
      "\n",
      "Use \"ollama [command] --help\" for more information about a command.\n"
     ]
    }
   ],
   "source": [
    "!ollama --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf80d6cb-3bd8-487b-997f-49e615211cdd",
   "metadata": {},
   "source": [
    "#### This model is required for embedding the additional information to the supplied query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ceaf8f-b33a-4af7-bfb3-8ac144622d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483b25c-cb2c-4eca-92ea-52e66d5f28ab",
   "metadata": {},
   "source": [
    "#### This is one of the basic ollama LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444fc411-90a5-40df-aa93-a62e80607a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 667b0c1932bc... 100% ▕████████████████▏ 4.9 GB                         \n",
      "pulling 948af2743fc7... 100% ▕████████████████▏ 1.5 KB                         \n",
      "pulling 0ba8f0e314b4... 100% ▕████████████████▏  12 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 455f34728c9b... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7dfd8a8-7280-439a-8f11-3fa16f265bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\u001b[?25l\u001b[?25h\u001b[2K\u001b[1G\u001b[?25hdeleted 'llama3.2'\n"
     ]
    }
   ],
   "source": [
    "!ollama rm llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b38620b-dd63-4980-9b01-7390f3c98acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED      \n",
      "llama3.1:latest            46e0c10c039e    4.9 GB    4 minutes ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    4 minutes ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c152fbd3-4d7d-4393-b44c-48a746c206cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b200a7-999d-4b6f-9ac6-ca25fa2c1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question):\n",
    "    response: ChatResponse = chat(model='llama3.1', messages=[\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': str(question),\n",
    "      },\n",
    "    ])\n",
    "    print(response.message.content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e251006-ecc4-49fa-967c-92e9ec1bddac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG, or Retrieval Augmented Generation, is a recent technique that has been gaining attention in the natural language processing (NLP) and artificial intelligence communities. It's an approach to building more effective and efficient language models by combining retrieval-based methods with generative models.\n",
      "\n",
      "**Traditional vs. RAG:**\n",
      "\n",
      "In traditional generative models, such as transformers or sequence-to-sequence models, the model generates a response from scratch based on its internal knowledge. However, this can lead to limitations like:\n",
      "\n",
      "1. Lack of contextual understanding\n",
      "2. Insufficient domain-specific knowledge\n",
      "\n",
      "To address these issues, RAG combines a retrieval module with a generative module.\n",
      "\n",
      "**How RAG works:**\n",
      "\n",
      "The Retrieval Module:\n",
      "\n",
      "1. Takes the input query as a prompt.\n",
      "2. Uses an index (e.g., a database or an external memory) to retrieve relevant documents or passages that are most relevant to the query.\n",
      "3. The retrieved documents are then used as contextual information for the Generative Module.\n",
      "\n",
      "The Generative Module:\n",
      "\n",
      "1. Takes the retrieved documents and the original input query as inputs.\n",
      "2. Uses this contextual information to generate a response, often with improved accuracy and relevance.\n",
      "\n",
      "**Benefits of RAG:**\n",
      "\n",
      "RAG offers several advantages over traditional generative models:\n",
      "\n",
      "1. **Improved accuracy**: By leveraging external knowledge from the retrieval module, RAG models can produce more accurate and informative responses.\n",
      "2. **Efficient use of resources**: RAG models don't require as much data to train as traditional generative models, making them more efficient in terms of computational resources and training time.\n",
      "3. **Better contextual understanding**: The retrieval module provides additional context, which helps the generative model generate more relevant and coherent responses.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "RAG has been successfully applied to various NLP tasks, including:\n",
      "\n",
      "1. Conversational AI\n",
      "2. Question Answering (QA)\n",
      "3. Text Summarization\n",
      "4. Language Translation\n",
      "\n",
      "Overall, RAG is an innovative approach that combines the strengths of retrieval-based methods with generative models, enabling more effective and efficient language understanding and generation.\n"
     ]
    }
   ],
   "source": [
    "ask('What is RAG (retrieval augmented generation)?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d32e73-ede0-4a86-b35a-7fa55ebf7cfb",
   "metadata": {},
   "source": [
    "#### The pdfreader translates any pdf document to text readable by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "59742336-ba28-4ad4-ad9f-b483638d3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"/home/mort/LaTeX/new projects/CRC5/main.pdf\")\n",
    "total_pages = len(reader.pages)\n",
    "all_text = \"\"\n",
    "for page_num in range(total_pages):\n",
    "    page = reader.pages[page_num]\n",
    "    all_text += page.extract_text()\n",
    "#print(all_text)\n",
    "f = open(\"/home/mort/temp/main.txt\", \"w\")\n",
    "f.write(all_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d2468-a48f-44c6-bef4-c8e489d5daf0",
   "metadata": {},
   "source": [
    "#### This starts a chroma embedding database as a docker container with entrypoint on port 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e60615e-1f18-4968-b50b-6a0adcb5914d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY        TAG       IMAGE ID       CREATED       SIZE\n",
      "chromadb/chroma   latest    1295eb7aaaed   5 days ago    469MB\n",
      "mort/crc5docker   latest    9f6ec881b8c5   4 weeks ago   5GB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b2944e2-fb59-4f99-9ec3-11db8f156796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE             COMMAND                  CREATED        STATUS                    PORTS     NAMES\n",
      "47137d05119e   chromadb/chroma   \"/docker_entrypoint.…\"   22 hours ago   Exited (0) 19 hours ago             chromadb\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2056d10-8d00-4719-aa11-fd2a83662012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chromadb\n"
     ]
    }
   ],
   "source": [
    "!docker start chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ac292-fa28-4fcb-a5dd-002b50a4fc6e",
   "metadata": {},
   "source": [
    "#### Code for preprocessing the RAG supplementary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3ad0df7-ee8e-46e9-b238-2399293e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def readtextfiles(path):\n",
    "  text_contents = {}\n",
    "  directory = os.path.join(path)\n",
    "\n",
    "  for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "      file_path = os.path.join(directory, filename)\n",
    "\n",
    "      with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "      text_contents[filename] = content\n",
    "\n",
    "  return text_contents\n",
    "\n",
    "def chunksplitter(text, chunk_size=100):\n",
    "  words = re.findall(r'\\S+', text)\n",
    "\n",
    "  chunks = []\n",
    "  current_chunk = []\n",
    "  word_count = 0\n",
    "\n",
    "  for word in words:\n",
    "    current_chunk.append(word)\n",
    "    word_count += 1\n",
    "\n",
    "    if word_count >= chunk_size:\n",
    "      chunks.append(' '.join(current_chunk))\n",
    "      current_chunk = []\n",
    "      word_count = 0\n",
    "\n",
    "  if current_chunk:\n",
    "    chunks.append(' '.join(current_chunk))\n",
    "\n",
    "  return chunks\n",
    "\n",
    "def getembedding(chunks):\n",
    "  embeds = ollama.embed(model=\"nomic-embed-text\", input=chunks)\n",
    "  return embeds.get('embeddings', [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f159d-9e67-4f56-af9a-2627d26f042b",
   "metadata": {},
   "source": [
    "#### Add the supplementary text to a database collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a88ecf52-8c8a-4b43-adc9-564521cb7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import ollama\n",
    "\n",
    "chromaclient = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "textdocspath = \"/home/mort/temp\"\n",
    "text_data = readtextfiles(textdocspath)\n",
    "\n",
    "collection = chromaclient.get_or_create_collection(name=\"ragwithpython\", metadata={\"hnsw:space\": \"cosine\"}  )\n",
    "\n",
    "for filename, text in text_data.items():\n",
    "  chunks = chunksplitter(text)\n",
    "  embeds = getembedding(chunks)\n",
    "  chunknumber = list(range(len(chunks)))\n",
    "  ids = [filename + str(index) for index in chunknumber]\n",
    "  metadatas = [{\"source\": filename} for index in chunknumber]\n",
    "  collection.add(ids=ids, documents=chunks, embeddings=embeds, metadatas=metadatas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9451e-7588-4db5-a87a-d96ee9a152b5",
   "metadata": {},
   "source": [
    "#### Execute a query with the supplementary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6bb63f1-670e-4c2c-ab7e-36333489509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answered with RAG: The iMAD (Iteratively Reweighted Multivariate Alteration Detection) change detection algorithm is a technique used to identify changes between two images by iteratively re-weighting the data based on the significance of the observed changes.\n",
      "\n",
      "Here's an overview of how the iMAD algorithm works, as described in the provided text:\n",
      "\n",
      "1. The algorithm starts with an initial iteration where the canonical correlations for each band are calculated.\n",
      "2. In each subsequent iteration, the P-values from the previous iteration are used to weight each pixel before re-sampling to determine the means and covariance matrices for the next iteration.\n",
      "3. This process continues until a stopping criterion is met, such as lack of significant change in the canonical correlations.\n",
      "\n",
      "The algorithm uses the following steps:\n",
      "\n",
      "1. Initialize the input data, which includes the two images to be compared and the number of iterations (maxitr).\n",
      "2. Iterate over the list of integers from 1 to maxitr using the `iterate` function.\n",
      "3. In each iteration, call the `imad` function with the current argument being an ee.Dictionary containing the bi-temporal image bands, and the prev argument being initialized to the first dictionary.\n",
      "4. The `imad` function performs the following steps:\n",
      "\t* Calculate the canonical correlations for each band.\n",
      "\t* Use the P-values from the previous iteration to weight each pixel before re-sampling to determine the means and covariance matrices for the next iteration.\n",
      "5. Continue iterating until the stopping criterion is met.\n",
      "\n",
      "The algorithm uses the following data structures:\n",
      "\n",
      "1. ee.Image: represents an image in the Earth Engine environment.\n",
      "2. ee.Dictionary: represents a dictionary of images or other data structures in the Earth Engine environment.\n",
      "\n",
      "The algorithm outputs the final MAD variates, which are used for change detection. The output can be visualized using tools such as the Google Earth Engine visualization tool or exported to assets such as TIFF files.\n",
      "\n",
      "Overall, the iMAD algorithm is an iterative re-weighting method that uses canonical correlations to detect changes between two images. It iteratively updates the weights of each pixel based on the significance of the observed changes, allowing it to adapt to changing conditions and improve detection accuracy over time.\n"
     ]
    }
   ],
   "source": [
    "query = \"describe the iMAD change detection algorithm\"\n",
    "\n",
    "queryembed = ollama.embed(model=\"nomic-embed-text\", input=query)['embeddings']\n",
    "\n",
    "relateddocs = '\\n\\n'.join(collection.query(query_embeddings=queryembed, n_results=10)['documents'][0])\n",
    "prompt = f\"{query} - Answer that question using the following text as a resource: {relateddocs}\"\n",
    "ragoutput = ollama.generate(model=\"llama3.1\", prompt=prompt, stream=False)\n",
    "\n",
    "print(f\"Answered with RAG: {ragoutput['response']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c283af62-167a-4203-be61-3ca2752f175a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
